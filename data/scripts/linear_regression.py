# Created by Messimeimei
# Updated with Global-Dim Normalization + Auto-Save LR Model (2025/11/21)

"""
è·¨å­¦ç§‘åˆ¤å®šäº”ç»´èåˆè®­ç»ƒè„šæœ¬ï¼ˆå…¨å±€å½’ä¸€åŒ– + è‡ªåŠ¨æ¨¡å‹ä¿å­˜ç‰ˆï¼‰
============================================================
æœ¬è„šæœ¬ç”¨äºä»äº”ä¸ªä¿¡æ¯æ¥æºï¼ˆäº”ç»´åº¦ï¼‰èåˆåˆ¤æ–­è®ºæ–‡ä¸»å­¦ç§‘/äº¤å‰å­¦ç§‘ã€‚

ä¸»è¦æ­¥éª¤ï¼š
1. è‡ªåŠ¨ç”Ÿæˆ/æ›´æ–°äº”ç»´èåˆè®­ç»ƒæ–‡ä»¶ 5dims_dataset.csv
2. è§£æäº”ç»´å­—æ®µæ•°æ®ï¼ˆäº”ç»´å¾—åˆ†ï¼‰
3. æå–å­¦ç§‘ä»£ç ï¼ˆç»Ÿä¸€ä¸º4ä½æ•°å­—ï¼Œå¦‚ 1205 / 0812ï¼‰
4. å°† CSV è½¬æ¢ä¸ºç»Ÿä¸€çš„ paper_data ç»“æ„
5. åŸºäºâ€œå…¨å±€ç»´åº¦å½’ä¸€åŒ–â€æ„é€ è®­ç»ƒç‰¹å¾ X ä¸æ ‡ç­¾ y
6. è®­ç»ƒé€»è¾‘å›å½’ LogisticRegressionï¼ˆäº”ç»´èåˆï¼‰
7. ç½‘æ ¼æœç´¢æœ€ä½³ threshold n ä¸ top-k
8. è‡ªåŠ¨ä¿å­˜æ¨¡å‹ï¼ˆmodel.pkl, global_stats.json, best_params.jsonï¼‰
============================================================
"""

import os
import json
import ast
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Tuple
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score
import pickle


# ================================================================
# Part 0 â€”â€” è‡ªåŠ¨ç”Ÿæˆ 5dims_dataset.csv
# ================================================================
def build_5dims_dataset(
    test_data_file: str,
    predicted_data_file: str,
    output_file: str = "../../data/5dims_dataset.csv"
):
    print("ğŸ“¥ è¯»å– test_data.csvï¼ˆçœŸå®æ ‡ç­¾ï¼‰...")
    test_df = pd.read_csv(test_data_file, dtype=str).fillna("")

    print("ğŸ“¥ è¯»å– predicted_result.csvï¼ˆå«äº”ç»´å­—æ®µï¼‰...")
    pred_df = pd.read_csv(predicted_data_file, dtype=str).fillna("")

    if "DOI" not in test_df.columns or "DOI" not in pred_df.columns:
        raise ValueError("test_data.csv ä¸ predicted_result.csv å¿…é¡»åŒ…å« DOI å­—æ®µ")

    print("ğŸ”„ æŒ‰ DOI åˆå¹¶æ•°æ® ...")
    merged = test_df.merge(pred_df, on="DOI", how="left", suffixes=("", "_pred"))

    required = [
        "DOI", "æ¥æº", "ç ”ç©¶æ–¹å‘", "è®ºæ–‡æ ‡é¢˜", "CR_æ‘˜è¦",
        "CR_ä½œè€…å’Œæœºæ„", "CR_å‚è€ƒæ–‡çŒ®DOI",
        "list_incites_direction", "list_title_abs",
        "list_author_aff_qwen", "list_openalex", "list_ref",
        "primary", "cross"
    ]
    for col in required:
        if col not in merged.columns:
            merged[col] = ""

    new_df = merged[required].copy()

    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    new_df.to_csv(output_file, index=False, encoding="utf-8-sig")

    print(f"ğŸ‰ 5dims_dataset.csv å·²ç”Ÿæˆ/æ›´æ–°ï¼Œå…± {len(new_df)} æ¡")
    return new_df


# ================================================================
# Part 1 â€”â€” äº”ç»´å­—æ®µè§£æ
# ================================================================
def safe_parse_list(s: str):
    if not isinstance(s, str) or s.strip() == "":
        return []
    try:
        return json.loads(s)
    except:
        try:
            return ast.literal_eval(s)
        except:
            return []


def extract_subject_code(field_name: str) -> str:
    if not isinstance(field_name, str) or field_name.strip() == "":
        return ""
    digits = "".join(c for c in field_name if c.isdigit())
    return digits[:4] if len(digits) >= 4 else ""


def clean_dim_items(raw_list):
    cleaned = []
    for item in raw_list:
        if isinstance(item, (list, tuple)) and len(item) >= 2:
            subject_code = extract_subject_code(str(item[0]))
            if subject_code == "":
                continue
            try:
                score = float(item[1])
            except:
                continue
            cleaned.append((subject_code, score))
    return cleaned


# ================================================================
# Part 2 â€”â€” 5dims_dataset â†’ paper_data
# ================================================================
def convert_csv_to_paper_data(csv_path: str):
    print(f"\nğŸ“¥ åŠ è½½ 5dims_dataset.csv: {csv_path}")
    df = pd.read_csv(csv_path, dtype=str).fillna("")

    paper_data = []

    for _, row in df.iterrows():
        dims = {
            "incites": clean_dim_items(safe_parse_list(row["list_incites_direction"])),
            "title_abs": clean_dim_items(safe_parse_list(row["list_title_abs"])),
            "author_aff": clean_dim_items(safe_parse_list(row["list_author_aff_qwen"])),
            "openalex": clean_dim_items(safe_parse_list(row["list_openalex"])),
            "refs": clean_dim_items(safe_parse_list(row["list_ref"])),
        }

        main_label = extract_subject_code(row["primary"])
        cross_codes = [
            extract_subject_code(x)
            for x in row["cross"].split("ï¼›")
            if extract_subject_code(x) != ""
        ]

        paper_data.append({
            "paper_id": row["DOI"].strip(),
            "dims": dims,
            "label": {"main": main_label, "cross": cross_codes},
        })

    print(f"ğŸ“¦ è½¬æ¢å®Œæˆï¼Œå…± {len(paper_data)} ç¯‡è®ºæ–‡")
    return paper_data


# ================================================================
# Part 3 â€”â€” å…¨å±€ min/max
# ================================================================
def compute_global_min_max(paper_data):
    dim_names = ["incites", "title_abs", "author_aff", "openalex", "refs"]

    stats = {name: [] for name in dim_names}

    for paper in paper_data:
        dims = paper["dims"]
        for name in dim_names:
            for _, score in dims.get(name, []):
                stats[name].append(float(score))

    global_stats = {}

    print("\nğŸ“Š å…¨å±€ min/max ç»Ÿè®¡ï¼š")
    for name, values in stats.items():
        if not values:
            print(f"  - {name}: EMPTY")
            global_stats[name] = (0, 1)
            continue
        mn, mx = min(values), max(values)
        print(f"  - {name}: min={mn:.4f}, max={mx:.4f}")
        global_stats[name] = (mn, mx)

    return global_stats


# ================================================================
# Part 4 â€”â€” å•ç»´å½’ä¸€åŒ–
# ================================================================
def normalize_dim_with_stats(dim_list, min_v, max_v):
    if not dim_list:
        return {}
    if min_v == max_v:
        return {f: 0.0 for f, _ in dim_list}
    return {f: (float(s) - min_v) / (max_v - min_v) for f, s in dim_list}


# ================================================================
# Part 5 â€”â€” æ„é€ è®­ç»ƒé›†
# ================================================================
def build_dataset(paper_data, global_stats):
    X_all, y_all, paper_index = [], [], []

    for paper in paper_data:
        dims = paper["dims"]

        inc = normalize_dim_with_stats(dims["incites"], *global_stats["incites"])
        tit = normalize_dim_with_stats(dims["title_abs"], *global_stats["title_abs"])
        aut = normalize_dim_with_stats(dims["author_aff"], *global_stats["author_aff"])
        ope = normalize_dim_with_stats(dims["openalex"], *global_stats["openalex"])
        ref = normalize_dim_with_stats(dims["refs"], *global_stats["refs"])

        fields = set(inc) | set(tit) | set(aut) | set(ope) | set(ref)

        main = paper["label"]["main"]
        cross = set(paper["label"]["cross"])

        for f in fields:
            X_all.append([
                inc.get(f, 0.0),
                tit.get(f, 0.0),
                aut.get(f, 0.0),
                ope.get(f, 0.0),
                ref.get(f, 0.0),
            ])
            y_all.append(1 if (f == main or f in cross) else 0)
            paper_index.append((paper["paper_id"], f))

    return np.array(X_all), np.array(y_all), paper_index


# ================================================================
# Part 6 â€”â€” è®­ç»ƒé€»è¾‘å›å½’
# ================================================================
def train_logistic(X, y):
    model = LogisticRegression(
        penalty="l2",
        C=1.0,
        max_iter=2000
    )
    model.fit(X, y)
    return model


# ================================================================
# Part 7 â€”â€” ç½‘æ ¼æœç´¢ n/k
# ================================================================
def search_threshold_k(model, paper_data, global_stats, thresholds=None, ks=None):
    if thresholds is None:
        thresholds = np.arange(0.2, 0.85, 0.05)
    if ks is None:
        ks = [1, 2, 3]

    best_f1, best_n, best_k = 0, 0.5, 1

    for n in thresholds:
        for k in ks:
            f1_list = []

            for paper in paper_data:
                dims = paper["dims"]

                inc = normalize_dim_with_stats(dims["incites"], *global_stats["incites"])
                tit = normalize_dim_with_stats(dims["title_abs"], *global_stats["title_abs"])
                aut = normalize_dim_with_stats(dims["author_aff"], *global_stats["author_aff"])
                ope = normalize_dim_with_stats(dims["openalex"], *global_stats["openalex"])
                ref = normalize_dim_with_stats(dims["refs"], *global_stats["refs"])

                fields = set(inc) | set(tit) | set(aut) | set(ope) | set(ref)
                if not fields:
                    continue

                true_set = {paper["label"]["main"], *paper["label"]["cross"]}

                preds = []
                for f in fields:
                    x = np.array([[inc.get(f, 0), tit.get(f, 0),
                                   aut.get(f, 0), ope.get(f, 0), ref.get(f, 0)]])
                    prob = model.predict_proba(x)[0][1]
                    preds.append((f, prob))

                filtered = [(f, p) for f, p in preds if p > n]
                if not filtered:
                    continue

                filtered.sort(key=lambda x: x[1], reverse=True)
                pred_main = filtered[0][0]
                pred_cross = [f for f, _ in filtered[1:k+1]]
                pred_set = {pred_main, *pred_cross}

                y_true = [1 if f in true_set else 0 for f in fields]
                y_pred = [1 if f in pred_set else 0 for f in fields]
                f1_list.append(f1_score(y_true, y_pred))

            if f1_list:
                avg_f1 = float(np.mean(f1_list))
                if avg_f1 > best_f1:
                    best_f1, best_n, best_k = avg_f1, float(n), int(k)

    return best_n, best_k, best_f1


# ================================================================
# Part 8 â€”â€” éšæœº 30 è®­ç»ƒ + 20 æµ‹è¯•
# ================================================================
def split_train_test(paper_data, train_size=30, random_seed=42):
    """
    éšæœºæŠ½æ ·ï¼š
    - 30 ä¸ªè®ºæ–‡è®­ç»ƒ
    - å‰©ä½™å…¨éƒ¨åšé¢„æµ‹
    """
    np.random.seed(random_seed)
    idx = np.arange(len(paper_data))
    np.random.shuffle(idx)

    train_idx = idx[:train_size]
    test_idx = idx[train_size:]

    train_data = [paper_data[i] for i in train_idx]
    test_data = [paper_data[i] for i in test_idx]

    print(f"\nğŸ“Œ éšæœºåˆ’åˆ†ï¼šè®­ç»ƒ {len(train_data)} ç¯‡ï¼Œæµ‹è¯• {len(test_data)} ç¯‡")
    return train_data, test_data


def train_pipeline_subset(train_data):
    print("\n=== Step 1ï¼šè®¡ç®—å…¨å±€ç»´åº¦ min/maxï¼ˆåŸºäºè®­ç»ƒé›†ï¼‰ ===")
    global_stats = compute_global_min_max(train_data)

    print("\n=== Step 2ï¼šæ„é€ è®­ç»ƒæ•°æ® X/y ===")
    X, y, _ = build_dataset(train_data, global_stats)
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(X)}, æ­£æ ·æœ¬æ¯”ä¾‹: {y.mean():.4f}")

    print("\n=== Step 3ï¼šè®­ç»ƒ LogisticRegression ===")
    model = train_logistic(X, y)
    print("äº”ç»´ coef_:", model.coef_[0])
    print("åç½® intercept_:", model.intercept_[0])

    return model, global_stats


# ================================================================
# Part 9 â€”â€” ä½¿ç”¨è®­ç»ƒé›† LR æ¨¡å‹é¢„æµ‹æµ‹è¯•é›†ä¸»å­¦ç§‘
# ================================================================
def predict_main_subject(model, test_data, global_stats):
    results = []

    print("\n=== Step 4ï¼šå¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ï¼ˆä»…ä¸»å­¦ç§‘ï¼‰ ===")

    for paper in test_data:
        dims = paper["dims"]

        inc = normalize_dim_with_stats(dims["incites"], *global_stats["incites"])
        tit = normalize_dim_with_stats(dims["title_abs"], *global_stats["title_abs"])
        aut = normalize_dim_with_stats(dims["author_aff"], *global_stats["author_aff"])
        ope = normalize_dim_with_stats(dims["openalex"], *global_stats["openalex"])
        ref = normalize_dim_with_stats(dims["refs"], *global_stats["refs"])

        fields = set(inc) | set(tit) | set(aut) | set(ope) | set(ref)
        if not fields:
            continue

        preds = []
        for f in fields:
            x = np.array([[inc.get(f, 0), tit.get(f, 0),
                           aut.get(f, 0), ope.get(f, 0), ref.get(f, 0)]])
            prob = model.predict_proba(x)[0][1]
            preds.append((f, prob))

        preds.sort(key=lambda x: x[1], reverse=True)
        pred_main = preds[0][0]  # å–æ¦‚ç‡æœ€å¤§çš„

        results.append({
            "paper_id": paper["paper_id"],
            "real_main": paper["label"]["main"],      # çœŸå®ä¸»å­¦ç§‘
            "pred_main": pred_main,                   # é¢„æµ‹ä¸»å­¦ç§‘
            "correct": pred_main == paper["label"]["main"],
            "top_prob": preds[0][1]
        })

    return results


# ================================================================
# å‡½æ•°ï¼šè®¡ç®—ä¸»å­¦ç§‘é¢„æµ‹å‡†ç¡®ç‡
# ================================================================
def compute_accuracy(results):
    correct = sum(1 for r in results if r["correct"])
    total = len(results)
    acc = correct / total if total > 0 else 0
    print(f"\nğŸ¯ ä¸»å­¦ç§‘é¢„æµ‹å‡†ç¡®ç‡ï¼š{acc:.4f}  ({correct}/{total})")
    return acc


# ================================================================
# ä¸»å…¥å£ï¼ˆè‡ªåŠ¨è·¯å¾„ + 30 è®­ç»ƒ / 20 é¢„æµ‹ + Accuracyï¼‰
# ================================================================
if __name__ == "__main__":

    from pathlib import Path

    ROOT = Path(__file__).resolve().parents[2]
    DATA_DIR = ROOT / "data"

    test_data_file = DATA_DIR / "test_data.csv"
    predicted_data_file = DATA_DIR / "predicted_result.csv"
    output_file = DATA_DIR / "5dims_dataset.csv"

    print("\n====== Step Aï¼šç”Ÿæˆ / æ›´æ–° 5dims_dataset.csv ======")
    build_5dims_dataset(str(test_data_file), str(predicted_data_file), str(output_file))

    print("\n====== Step Bï¼šè½¬æ¢ä¸º paper_data ======")
    paper_data = convert_csv_to_paper_data(str(output_file))

    # -----------------------------
    # ğŸ¯ éšæœºåˆ’åˆ† 30 / å‰©ä½™ 20
    # -----------------------------
    train_data, test_data = split_train_test(paper_data, train_size=30)

    # -----------------------------
    # ğŸ¯ å¯¹ 30 ä¸ªè®­ç»ƒ
    # -----------------------------
    model, global_stats = train_pipeline_subset(train_data)

    # -----------------------------
    # ğŸ¯ å¯¹å‰©ä¸‹ test_data åšé¢„æµ‹
    # -----------------------------
    results = predict_main_subject(model, test_data, global_stats)

    print("\n====== é€æ¡é¢„æµ‹ç»“æœ ======")
    for r in results:
        print(f"{r['paper_id']} | çœŸ={r['real_main']} | é¢„æµ‹={r['pred_main']} | "
              f"prob={r['top_prob']:.4f} | correct={r['correct']}")

    # -----------------------------
    # ğŸ¯ è®¡ç®—ä¸»å­¦ç§‘ Accuracy
    # -----------------------------
    compute_accuracy(results)

    print("\nğŸ‰ å®Œæˆï¼")
