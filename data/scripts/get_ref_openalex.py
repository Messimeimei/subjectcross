# -*- coding: utf-8 -*-
# Created by Messimeimei
"""
å¢é‡æ“ä½œï¼Œä¸ºæ‰€æœ‰çš„å‚è€ƒæ–‡çŒ®è·å– OpenAlex å­¦ç§‘å¹¶æ˜ å°„è‡³ä¸­å›½ä¸€çº§å­¦ç§‘ï¼Œåœ¨ä¸Šä¸€æ­¥çš„csvæ–‡ä»¶åŸºç¡€ä¸Šæ–°å¢2åˆ—ï¼š
- Ref_OpenAlex_topicsï¼šå‚è€ƒæ–‡çŒ®çš„ OpenAlex å­¦ç§‘ä¸»é¢˜åˆ—è¡¨ï¼Œæ ¼å¼ä¸º[[[field1, field2], [subfield1]], ...]
- Ref_OpenAlex_map_subjectsï¼šå‚è€ƒæ–‡çŒ®çš„æ˜ å°„ä¸­å›½ä¸€çº§å­¦ç§‘åˆ—è¡¨ï¼Œæ ¼å¼ä¸º[[[subject1, score1], [subject2, score2]], ...]
æ•°æ®ä½äºdata/03openalex_dataç›®å½•ä¸‹ï¼Œæ–‡ä»¶åä¸è¾“å…¥æ–‡ä»¶ç›¸åŒ
"""

import os
import json
import time
import random
import requests
import pandas as pd
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from typing import List, Dict, Any


class RefOpenAlexMapper:
    """
    è¿™ä¸ªç±»å®Œæˆæ•°æ®é›†æ„å»ºçš„ç¬¬äºŒé˜¶æ®µï¼šä»02crossref_dataç›®å½•è·å–åŸå§‹æ•°æ®ï¼Œ
    å¹¶é€šè¿‡OpenAlex APIä¸ºå‚è€ƒæ–‡çŒ®çš„æ‰€æœ‰è®ºæ–‡æŠ“å–è¡¥å……å…ƒæ•°æ®ï¼Œæœ€åä¿å­˜åˆ°03openalex_dataå¯¹åº”å­¦ç§‘csvæ–‡ä»¶ä¸­
    """
    def __init__(self,
                 input_file: str,
                 origin_file: str = None,
                 output_dir: str = "data/03openalex_data",
                 openalex_email: str = "3170529323@qq.com"):

        ROOT_DIR = Path(__file__).resolve().parents[2]
        self.input_file = (ROOT_DIR / input_file).resolve()

        if origin_file:
            origin_path = (ROOT_DIR / origin_file).resolve()
            if origin_path.is_dir():
                expected = origin_path / self.input_file.name
                if expected.exists():
                    print(f"ğŸ”— åŸºçº¿æ–‡ä»¶åŒ¹é…æˆåŠŸ: {expected.name}")
                    origin_path = expected
                else:
                    print(f"âš ï¸ æœªæ‰¾åˆ°å¯¹åº”åŸºçº¿æ–‡ä»¶: {expected.name}ï¼Œè§†ä¸ºé¦–æ¬¡è¿è¡Œï¼ˆå…¨é‡å¤„ç†ï¼‰")
                    origin_path = None
            self.origin_file = origin_path
        else:
            self.origin_file = None

        self.output_dir = (ROOT_DIR / output_dir).resolve()
        self.map_path = ROOT_DIR / "data/deepseek_map.json"
        self.openalex_email = openalex_email

        os.makedirs(self.output_dir, exist_ok=True)
        self.df_mapped = None

    # ================== Step 1ï¼šè·å–æ–°å¢è®ºæ–‡æ•°æ®ï¼Œä»¥ DOI ==================
    def load_incremental_data(self) -> pd.DataFrame:
        """
        è¯»å–å½“å‰æ•°æ®csvæ–‡ä»¶å’ŒåŸå§‹æ•°æ®çš„csvæ–‡ä»¶ï¼Œå¯¹æ¯”æ±‚æ–°å¢ DOI å·®é›†
        """

        # è¯»å–å½“å‰æ•°æ®ï¼Œdfæ ¼å¼
        abs_input = str(self.input_file.resolve())
        print(f"\nğŸ“˜ åŠ è½½æœ€æ–°æ•°æ®: {self.input_file.name}")
        print(f"    â†³ è·¯å¾„: {abs_input}")
        df_new = pd.read_csv(self.input_file, encoding="utf-8-sig")

        # å¦‚æœæ²¡æœ‰åŸå§‹æ•°æ®ï¼Œåˆ™å¯¹å½“å‰æ•°æ®æ‰€æœ‰è®ºæ–‡æ‰§è¡Œæ“ä½œ
        if not self.origin_file or not Path(self.origin_file).exists():
            print("âš ï¸ æ— åŸºçº¿æ•°æ®ï¼Œé¦–æ¬¡æ‰§è¡Œ â†’ å…¨é‡å¤„ç†")
            df_new["is_new"] = True
            return df_new

        # è¯»å–åŸå§‹æ•°æ®ï¼Œdfæ ¼å¼
        abs_origin = str(Path(self.origin_file).resolve())
        print(f"ğŸ“˜ åŠ è½½åŸºçº¿æ•°æ®: {Path(self.origin_file).name}")
        print(f"    â†³ è·¯å¾„: {abs_origin}")
        df_old = pd.read_csv(self.origin_file, encoding="utf-8-sig")
    
        # è®¡ç®—æ–°å¢ DOI å·®é›†
        new_doi_set = set(df_new["DOI"].astype(str))
        old_doi_set = set(df_old["DOI"].astype(str))
        added_dois = new_doi_set - old_doi_set

        print(f"ğŸ” å½“å‰ {len(new_doi_set)} æ¡ï¼ŒåŸºçº¿ {len(old_doi_set)} æ¡ â†’ æ–°å¢ {len(added_dois)} æ¡")
        df_new["is_new"] = df_new["DOI"].astype(str).isin(added_dois)

        return df_new[df_new["is_new"]].reset_index(drop=True)

    # ================== Step 2ï¼šä¸ºå‚è€ƒæ–‡çŒ®è·å– Openalex æ•°æ® ==================
    def safe_request(self, url, headers, retries=3):
        # ä¸ºå•ç¯‡å‚è€ƒæ–‡çŒ®è·å– OpenAlex æ•°æ®ï¼Œæœ€å¤šé‡è¯• retries æ¬¡ï¼Œå¦åˆ™è¿”å›ç©º
        for attempt in range(retries):
            try:
                time.sleep(random.uniform(0.6, 1.2))
                r = requests.get(url, headers=headers, timeout=25)
                if r.status_code == 429:
                    wait = 5 * (attempt + 1)
                    print(f"âš ï¸ 429 Too Many Requestsï¼Œç­‰å¾… {wait}s...")
                    time.sleep(wait)
                    continue
                if r.status_code == 404:
                    return None
                r.raise_for_status()
                return r.json()
            except Exception:
                time.sleep(2)
        return None

    def get_openalex_topics(self, doi: str) -> Dict[str, List[str]]:
        # å…·ä½“æ‰§è¡Œä¸ºå•ç¯‡å‚è€ƒæ–‡çŒ®è·å– OpenAlex å­¦ç§‘ä¸»é¢˜çš„æ“ä½œ

        url = f"https://api.openalex.org/works/https://doi.org/{doi}"
        headers = {"User-Agent": f"OpenAlex-Client (mailto:{self.openalex_email})"}
        data = self.safe_request(url, headers)

        if not data:
            return {"fields": [], "subfields": []}

        # è§£æå•ç¯‡è®ºæ–‡çš„ OpenAlex å­¦ç§‘ä¸»é¢˜
        topics = data.get("topics") or []
        primary = data.get("primary_topic") or None
        fields, subfields = set(), set()
        get_name = lambda o: o.get("display_name") if isinstance(o, dict) else str(o)

        for t in topics:
            f, s = get_name(t.get("field")), get_name(t.get("subfield"))
            if f: fields.add(f)
            if s: subfields.add(s)

        if primary:
            f, s = get_name(primary.get("field")), get_name(primary.get("subfield"))
            if f: fields.add(f)
            if s: subfields.add(s)

        return {"fields": list(fields), "subfields": list(subfields)}

    # ================== Step 3ï¼šä¸­å›½å­¦ç§‘æ˜ å°„ ==================
    def load_mapping_table(self):
        # åŠ è½½ä¸­å›½å­¦ç§‘æ˜ å°„è¡¨
        if not self.map_path.exists():
            raise RuntimeError(f"âŒ æ˜ å°„è¡¨ç¼ºå¤±: {self.map_path}")
        with open(self.map_path, "r", encoding="utf-8") as f:
            print(f"âœ… æ˜ å°„è¡¨å·²åŠ è½½: {self.map_path}")
            return json.load(f)

    # ================== Step 4ï¼šä¸»æ‰§è¡Œæµç¨‹ ==================
    def process_ref_openalex(self, max_ref_per_paper=20, max_workers=8, max_rows=None):
        """
        ä¸ºæ–°å¢çš„è®ºæ–‡å‚è€ƒæ–‡çŒ®è·å– OpenAlex å­¦ç§‘ä¸»é¢˜å¹¶æ˜ å°„è‡³ä¸­å›½ä¸€çº§å­¦ç§‘
        """
        
        df_new = self.load_incremental_data()
        if df_new.empty:
            print("âœ… æ— æ–°å¢è®ºæ–‡ï¼Œè·³è¿‡æ‰§è¡Œ")
            return None

        mapping_dict = self.load_mapping_table()

        # é™åˆ¶å¤„ç†æ¡æ•°ï¼Œä¹Ÿæ˜¯æ–¹ä¾¿æµ‹è¯•ï¼Œé»˜è®¤ä¸é™åˆ¶å…¨éƒ¨å¤„ç†æ–°å¢è®ºæ–‡
        if max_rows and len(df_new) > max_rows:
            print(f"âš ï¸ æ–°å¢ {len(df_new)} æ¡ï¼Œä»…å¤„ç†å‰ {max_rows} æ¡")
            df_new = df_new.head(max_rows)

        print(f"ğŸ” å¼€å§‹æŠ“å–å‚è€ƒæ–‡çŒ®å­¦ç§‘æ˜ å°„ï¼ˆæ–°å¢ {len(df_new)} æ¡ï¼‰...")

        topics_results = [None] * len(df_new)
        mapped_results = [None] * len(df_new)
        success_count = 0

        # å¹¶å‘æŠ“å–å‚è€ƒæ–‡çŒ®çš„ OpenAlex å­¦ç§‘ä¸»é¢˜å¹¶æ˜ å°„
        def fetch(ref_dois):
            ref_topics, ref_cn = [], []
            for ref_doi in ref_dois[:max_ref_per_paper]:
                # è·å–å•ç¯‡å‚è€ƒæ–‡çŒ®çš„ OpenAlex å­¦ç§‘ä¸»é¢˜
                topic = self.get_openalex_topics(ref_doi)
                if not topic["fields"] and not topic["subfields"]:
                    continue
                ref_topics.append([topic["fields"], topic["subfields"]])

                # ä¸ºå•ç¯‡å‚è€ƒæ–‡çŒ®çš„å­¦ç§‘ä¸»é¢˜æ˜ å°„ä¸­å›½ä¸€çº§å­¦ç§‘
                mapped = []
                for name in topic["fields"] + topic["subfields"]:
                    for subj, score in mapping_dict.get(name, []):
                        mapped.append([subj, float(score)])
                
                # ä¿å­˜å•ç¯‡å‚è€ƒæ–‡çŒ®çš„åŸå§‹ç»“æœå’Œæ˜ å°„ç»“æœ
                ref_cn.append(mapped)
            return ref_topics, ref_cn

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {}
            for idx, row in df_new.iterrows():
                try:
                    ref_dois = json.loads(row["CR_å‚è€ƒæ–‡çŒ®DOI"])
                    if ref_dois:
                        futures[executor.submit(fetch, ref_dois)] = idx
                except:
                    pass

            for future in tqdm(as_completed(futures), total=len(futures),
                               desc="Fetching Reference Topics", ncols=90):
                idx = futures[future]
                try:
                    topics, mapped = future.result()
                    if mapped: success_count += 1
                    topics_results[idx] = topics
                    mapped_results[idx] = mapped
                except Exception:
                    topics_results[idx] = []
                    mapped_results[idx] = []

        # ä¸ºæ–°å¢è®ºæ–‡æ·»åŠ 2åˆ—ç»“æœ
        df_new["Ref_OpenAlex_topics"] = topics_results
        df_new["Ref_OpenAlex_map_subjects"] = mapped_results

        # è¿‡æ»¤å­¦ç§‘ä¸ºç©ºçš„ç»“æœï¼Œåˆ é™¤is_newä¸´æ—¶åˆ—
        df_new = df_new[df_new["Ref_OpenAlex_map_subjects"].apply(lambda x: isinstance(x, list) and len(x) > 0)]
        df_new = df_new.drop(columns=["is_new"], errors="ignore")

        print(f"âœ… æ–°å¢è®ºæ–‡ {len(futures)} æ¡ï¼Œå…¶ä¸­æˆåŠŸè·å– OpenAlex æ•°æ® {success_count} æ¡")

        # å°†æ–°å¢æ•°æ®ä¸ç›®æ ‡æ–‡ä»¶å†…å®¹åˆå¹¶
        out_path = (self.output_dir / self.input_file.name).resolve()
        print(f"\nğŸ’¾ è¾“å‡ºç›®æ ‡æ–‡ä»¶: {out_path}")

        if out_path.exists():
            df_old = pd.read_csv(out_path, encoding="utf-8-sig")
            old_dois = set(df_old["DOI"].astype(str))
            df_append = df_new[~df_new["DOI"].astype(str).isin(old_dois)]
            df_all = pd.concat([df_old, df_append], ignore_index=True)
            print(f"ğŸ§© åŸæ–‡ä»¶ {len(df_old)} æ¡ï¼Œè¿½åŠ  {len(df_append)} æ¡ â†’ åˆè®¡ {len(df_all)} æ¡")
        else:
            df_all = df_new

        # ä¿å­˜åŠ å…¥æ–°å¢æ•°æ®åçš„å®Œæ•´æ–‡ä»¶
        df_all.to_csv(out_path, index=False, encoding="utf-8-sig")
        self.df_mapped = df_all
        print(f"âœ… å·²ä¿å­˜ç»“æœ â†’ {out_path}")

    # ================== Step 5ï¼šç»Ÿè®¡ ==================
    def print_statistics(self):
        if self.df_mapped is None:
            print("âš ï¸ æ— ç»“æœå¯ç»Ÿè®¡")
            return
        total = len(self.df_mapped)
        valid = 0
        for v in self.df_mapped["Ref_OpenAlex_map_subjects"]:
            try:
                if isinstance(v, list) and len(v) > 0:
                    valid += 1
            except:
                pass
        print(f"\nğŸ“Š ç»Ÿè®¡: æ€»è®ºæ–‡ {total} | æˆåŠŸæ˜ å°„ {valid} ({valid/total:.1%})")



# ================== å•æ–‡ä»¶æµ‹è¯•å…¥å£ ==================
if __name__ == "__main__":
    mapper = RefOpenAlexMapper(
        input_file="data/02crossref_data/0802 Mechanical Engineering.csv",
        origin_file="data/02origin_crossref_data",
        output_dir="data/03openalex_data",
    )
    mapper.process_ref_openalex(max_ref_per_paper=5, max_workers=5)
    mapper.print_statistics()
