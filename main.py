# -*- coding: utf-8 -*-
"""
ä¸»ç¨‹åºå…¥å£ - æ‰¹é‡å¤„ç†å­¦ç§‘æ•°æ®ï¼ˆæ”¯æŒå•æ–‡ä»¶/å•ç›®å½•è¿è¡Œï¼‰
---------------------------------------------------------
æ–°å¢åŠŸèƒ½ï¼š
  âœ… --file å‚æ•°ï¼šæŒ‡å®šå•ä¸ª CSV æ–‡ä»¶è¿›è¡Œå¤„ç†ï¼ˆé€‚ç”¨äº getref / getinput / getrankï¼‰
  âœ… --dir å‚æ•°ï¼šæŒ‡å®šå•ä¸ªç›®å½•è¿è¡Œï¼ˆé€‚ç”¨äº getmeta é˜¶æ®µï¼‰
  âœ… è‡ªåŠ¨åˆ¤æ–­è·¯å¾„ç±»å‹ï¼ˆå•æ–‡ä»¶ / æ‰¹é‡æ¨¡å¼ï¼‰
---------------------------------------------------------
"""

from utils.subject_calculator import SubjectCalculator
from tqdm import tqdm
import os
import sys
from pathlib import Path
from data.scripts.get_by_crossref_openalex import CrossrefMetaProcessor
import json
import pandas as pd

BASE_DIR = Path(__file__).resolve().parent
os.chdir(BASE_DIR)
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

try:
    from data.scripts.get_ref_openalex import RefOpenAlexMapper
except Exception as e:
    RefOpenAlexMapper = None


# ====================== åŸºç¡€å·¥å…· ======================

def get_all_subdirectories(root_dir: str) -> list:
    """è·å–æ ¹ç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•"""
    return sorted([os.path.join(root_dir, d) for d in os.listdir(root_dir)
                   if os.path.isdir(os.path.join(root_dir, d))])


def get_existing_files(directory: str) -> set:
    """è·å–ç›®å½•ä¸­å·²æœ‰çš„CSVæ–‡ä»¶åé›†åˆ"""
    if not os.path.exists(directory):
        return set()
    return {f for f in os.listdir(directory) if f.endswith(".csv")}


# ====================== æ ¸å¿ƒé˜¶æ®µå‡½æ•° ======================

def get_crossref_openalex(input_dir: str, base_output_dir="data/02crossref_data", limit=8000):
    """æ‰§è¡Œ Crossref + OpenAlex æŠ“å–"""
    dir_name = os.path.basename(input_dir)
    print(f"ğŸ” å¤„ç†ç›®å½•: {dir_name}")

    try:
        processor = CrossrefMetaProcessor(input_dir=input_dir, output_dir=base_output_dir, origin_dir='data/01origin_meta_data')
        output_file = processor.merge_metadata_with_crossref(limit=limit)
        processor.print_statistics()
        print(f"âœ… å¤„ç†å®Œæˆ: {dir_name}")
        return output_file
    except Exception as e:
        import traceback
        print(f"âŒ å‡ºé”™: {dir_name} â†’ {e}")
        traceback.print_exc()
        return None


def batch_make_all_inputs(openalex_dir="data/03openalex_data",
                          mapping_csv="data/zh_disciplines.csv",
                          output_dir="data/04input_data",
                          file_path=None):
    """ç”Ÿæˆç»Ÿä¸€è¾“å…¥æ–‡ä»¶ï¼ˆè‡ªåŠ¨æ”¯æŒå¢é‡é€»è¾‘ï¼‰"""
    from data.scripts.make_input import make_all_lists
    os.makedirs(output_dir, exist_ok=True)

    if file_path:
        files = [os.path.basename(file_path)]
        openalex_dir = os.path.dirname(file_path)
    else:
        files = sorted([f for f in os.listdir(openalex_dir) if f.endswith(".csv")])

    print(f"ğŸ“š å…± {len(files)} ä¸ªæ–‡ä»¶å¾…å¤„ç†")
    for fname in files:
        input_path = os.path.join(openalex_dir, fname)
        print(f"\nâ¡ï¸ {fname}")

        try:
            # ğŸ”¹ è°ƒç”¨æ–°ç‰ˆ make_all_lists()ï¼Œæ”¯æŒå¢é‡
            make_all_lists(
                input_file=input_path,
                mapping_csv=mapping_csv,
                origin_file="data/03origin_openalex_data",
                output_dir=output_dir
            )
            print("   âœ… æˆåŠŸç”Ÿæˆï¼ˆå«å¢é‡å¤„ç†ï¼‰")
        except Exception as e:
            import traceback
            print(f"   âŒ å¤±è´¥: {e}")
            traceback.print_exc()


def refrank_with_llm_and_stub_result(
    input_dir="data/04input_data",
    output_dir="data/05output_data",
    overwrite=False,
    file_path=None,
):
    """é˜¶æ®µå››ï¼šç›´æ¥è®¡ç®—å­¦ç§‘ç»“æœï¼ˆå¯æŒ‡å®šå•ä¸ªæ–‡ä»¶ï¼‰"""
    os.makedirs(output_dir, exist_ok=True)
    files = [os.path.basename(file_path)] if file_path else sorted(
        [f for f in os.listdir(input_dir) if f.endswith(".csv")]
    )
    if file_path:
        input_dir = os.path.dirname(file_path)

    print(f"ğŸ§  å­¦ç§‘è®¡ç®—é˜¶æ®µï¼šå…± {len(files)} ä¸ªæ–‡ä»¶")
    calc = SubjectCalculator(debug=True, strategy="weighted",topk_cross=3)

    for fname in files:
        in_csv = os.path.join(input_dir, fname)
        out_csv = os.path.join(output_dir, fname)
        print(f"\nâ¡ï¸ {fname}")

        if not overwrite and os.path.exists(out_csv):
            print("   â­ï¸ å·²å­˜åœ¨ï¼Œè·³è¿‡")
            continue

        try:
            df = pd.read_csv(in_csv, dtype=str).fillna("")
        except Exception as e:
            print(f"   âŒ è¯»å–å¤±è´¥ï¼š{e}")
            continue

        results_json = []
        for _, row in tqdm(df.iterrows(), total=len(df), desc="  âš™ï¸ è®¡ç®—", ncols=90, leave=False):
            try:
                res = calc.calc(row)
                results_json.append(json.dumps(res, ensure_ascii=False))
            except Exception:
                results_json.append("{}")

        df["result"] = results_json
        df["primary"] = df["result"].apply(lambda x: json.loads(x).get("primary"))
        df["cross"] = df["result"].apply(lambda x: ",".join(json.loads(x).get("cross", [])))
        df["detail"] = df["result"].apply(
            lambda x: json.dumps(json.loads(x).get("detail", {}), ensure_ascii=False)
        )

        try:
            df.to_csv(out_csv, index=False, encoding="utf-8-sig")
            print(f"   ğŸ’¾ ä¿å­˜å®Œæˆ: {out_csv}")
        except Exception as e:
            print(f"   âŒ å†™å‡ºå¤±è´¥: {e}")


# ====================== ä¸»æ§åˆ¶å…¥å£ ======================

def main(mode="all", file_path=None, dir_path=None):
    """ä¸»ç¨‹åºå…¥å£ï¼ˆæ”¯æŒå•æ–‡ä»¶/å•ç›®å½•è¿è¡Œï¼‰"""
    ROOT_DIR = "data/01meta_data"
    PROCESSED_DIR = "data/02crossref_data"
    OPENALEX_REF_DIR = "data/03openalex_data"
    RESULT_DIR = "data/05output_data"

    print("=" * 60)
    print(f"ğŸš€ å¯åŠ¨æ‰¹å¤„ç†ç¨‹åº  | æ¨¡å¼: {mode}")
    print("=" * 60)

    # ---------------- getmeta ----------------
    if mode in ("getmeta", "all"):
        print("\nğŸ§© é˜¶æ®µ 1ï¼šCrossref & OpenAlex å…ƒæ•°æ®è·å–")
        targets = [dir_path] if dir_path else get_all_subdirectories(ROOT_DIR)
        for i, subdir in enumerate(targets, 1):
            print(f"[{i}/{len(targets)}] {os.path.basename(subdir)}")
            get_crossref_openalex(subdir, PROCESSED_DIR)

    # ---------------- getref ----------------
    if mode in ("getref", "all"):
        if RefOpenAlexMapper is None:
            print("âŒ ç¼ºå°‘ RefOpenAlexMapper å®ç°æ–‡ä»¶")
            return 1

        print("\nğŸ“š é˜¶æ®µ 2ï¼šå‚è€ƒæ–‡çŒ® OpenAlex æ˜ å°„")
        files = [os.path.basename(file_path)] if file_path else sorted(get_existing_files(PROCESSED_DIR))
        input_dir = os.path.dirname(file_path) if file_path else PROCESSED_DIR
        for fname in files:
            input_csv = os.path.join(input_dir, fname)
            output_csv = os.path.join(OPENALEX_REF_DIR, fname)
            print(f"â¡ï¸ {fname}")
            # if os.path.exists(output_csv):
            #     print("   â­ï¸ å·²å­˜åœ¨ï¼Œè·³è¿‡")
            #     continue
            mapper = RefOpenAlexMapper(input_csv, output_dir=OPENALEX_REF_DIR, origin_file='data/02origin_crossref_data')
            mapper.process_ref_openalex(max_ref_per_paper=10)
            mapper.print_statistics()
            print("   âœ… å®Œæˆ")

    # ---------------- getinput ----------------
    if mode in ("getinput", "all"):
        print("\nğŸ§© é˜¶æ®µ 3ï¼šç”Ÿæˆç»Ÿä¸€è¾“å…¥æ–‡ä»¶")
        batch_make_all_inputs(
            openalex_dir="data/03openalex_data",
            mapping_csv="data/zh_disciplines.csv",
            output_dir="data/04input_data",
            file_path=file_path,
        )

    # ---------------- getrank ----------------
    if mode in ("getrank", "all"):
        print("\nğŸ¤– é˜¶æ®µ 4ï¼šå­¦ç§‘è®¡ç®—")
        refrank_with_llm_and_stub_result(
            input_dir="data/04input_data",
            output_dir="data/05output_data",
            overwrite=False,
            file_path=file_path,
        )

    print("\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
    return 0


# ====================== CLI è°ƒç”¨ ======================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="æ‰¹é‡å¤„ç†å­¦ç§‘æ•°æ®ï¼ˆæ”¯æŒå•æ–‡ä»¶æˆ–å•ç›®å½•è¿è¡Œï¼‰")
    parser.add_argument("--mode",
                        choices=["getmeta", "getref", "getinput", "getrank", "all"],
                        default="all",
                        help="æ‰§è¡Œé˜¶æ®µ")
    parser.add_argument("--file", type=str, default=None,
                        help="æŒ‡å®šå•ä¸ªCSVæ–‡ä»¶ï¼ˆç”¨äº getref/getinput/getrankï¼‰")
    parser.add_argument("--dir", type=str, default=None,
                        help="æŒ‡å®šå•ä¸ªç›®å½•ï¼ˆç”¨äº getmetaï¼‰")

    args = parser.parse_args()
    exit(main(mode=args.mode, file_path=args.file, dir_path=args.dir))
