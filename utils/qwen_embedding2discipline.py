import torch
import torch.nn.functional as F
from torch import Tensor
from transformers import AutoTokenizer, AutoModel
import numpy as np
from typing import List, Tuple, Dict
from dotenv import load_dotenv
import pandas as pd
import os
import glob
from typing import List, Tuple
import json
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class QwenDisciplineScorer:
    """
    ä½¿ç”¨Qwen3-Embeddingæ¨¡å‹è¿›è¡Œå­¦ç§‘åˆ†ç±»ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼‰
    """
    
    def __init__(self, model_path: str = None, use_flash_attention: bool = False, device: str = None):
        """
        åˆå§‹åŒ–æ¨¡å‹
        
        :param model_path: æ¨¡å‹è·¯å¾„ï¼ŒNoneåˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        :param use_flash_attention: æ˜¯å¦ä½¿ç”¨flash attentionåŠ é€Ÿï¼ˆé»˜è®¤å…³é—­ä»¥å‡å°‘å†…å­˜ï¼‰
        :param device: è®¾å¤‡ç±»å‹ï¼ŒNoneåˆ™è‡ªåŠ¨æ£€æµ‹
        """
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        self.model_path = model_path or os.getenv("EMB_MODEL_NAME", "../../models/Qwen3-Embedding-0.6B")
        self.batch_size = int(os.getenv("BATCH_SIZE", "16"))  # å‡å°æ‰¹å¤§å°
        self.use_fp16 = os.getenv("USE_FP16", "false").lower() == "true"  # é»˜è®¤å…³é—­FP16
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        
        print(f"ğŸ¤– åŠ è½½Qwen3-Embeddingæ¨¡å‹: {self.model_path}")
        print(f"âš™ï¸ é…ç½® - è®¾å¤‡: {self.device}, æ‰¹å¤§å°: {self.batch_size}, FP16: {self.use_fp16}")
        
        # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.model_path}")
        
        # åŠ è½½tokenizerå’Œæ¨¡å‹
        print("ğŸ“¥ åŠ è½½tokenizer...")
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_path, 
            trust_remote_code=True,
            padding_side='left'
        )
        
        print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
        try:
            # ä½¿ç”¨æ›´ä¿å®ˆçš„è®¾ç½®ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
            model_kwargs = {
                "trust_remote_code": True,
                "torch_dtype": torch.float16 if self.use_fp16 else torch.float32,
                "low_cpu_mem_usage": True,
            }
            
            # åªåœ¨æ˜ç¡®è¦æ±‚ä¸”å†…å­˜å……è¶³æ—¶ä½¿ç”¨flash attention
            if use_flash_attention and torch.cuda.is_available():
                try:
                    model_kwargs["attn_implementation"] = "flash_attention_2"
                    print("âš¡ ä½¿ç”¨Flash Attention 2")
                except Exception as e:
                    print(f"âš ï¸ Flash Attention 2ä¸å¯ç”¨: {e}")
            
            self.model = AutoModel.from_pretrained(self.model_path, **model_kwargs)
            
            # ç§»åŠ¨åˆ°è®¾å¤‡
            if self.device == "cuda":
                self.model = self.model.cuda()
            else:
                self.model = self.model.to(self.device)
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
            
        self.max_length = 2048  # å‡å°æœ€å¤§é•¿åº¦
        
        # å­¦ç§‘ä»»åŠ¡æè¿°
        self.task_description = "ç»™å®šä¸€ç¯‡å­¦æœ¯è®ºæ–‡çš„æ ‡é¢˜å’Œæ‘˜è¦ï¼Œåˆ¤æ–­å…¶æ‰€å±çš„å­¦ç§‘é¢†åŸŸ"
        
        # åŠ è½½å­¦ç§‘ä¿¡æ¯
        self.code2name, self.code2intro = self.load_disciplines()
        
    def last_token_pool(self, last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:
        """
        ä½¿ç”¨last token poolingè·å–å¥å­è¡¨ç¤º
        """
        left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])
        if left_padding:
            return last_hidden_states[:, -1]
        else:
            sequence_lengths = attention_mask.sum(dim=1) - 1
            batch_size = last_hidden_states.shape[0]
            return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]
    
    def get_detailed_instruct(self, query: str) -> str:
        """
        æ„å»ºæŒ‡ä»¤æ ¼å¼
        """
        return f'Instruct: {self.task_description}\nQuery: {query}'
    
    def load_disciplines(self) -> Tuple[Dict, Dict]:
        """
        åŠ è½½å­¦ç§‘ä¿¡æ¯ï¼Œä»ç¯å¢ƒå˜é‡æŒ‡å®šçš„è·¯å¾„
        """
        json_path = os.getenv("JSON_PATH", "../zh_discipline_intro.json")
        csv_path = os.getenv("CSV_PATH", "../zh_disciplines.csv")
        
        # ç¡®ä¿è·¯å¾„æ˜¯ç»å¯¹è·¯å¾„
        if not os.path.isabs(json_path):
            current_dir = os.path.dirname(os.path.abspath(__file__))
            json_path = os.path.join(current_dir, json_path)
            csv_path = os.path.join(current_dir, csv_path)
            
        print(f"ğŸ“š åŠ è½½å­¦ç§‘æ•°æ®: {json_path}")
        
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                discipline_data = json.load(f)
        except Exception as e:
            print(f"âŒ åŠ è½½å­¦ç§‘JSONæ–‡ä»¶å¤±è´¥: {e}")
            return self._load_disciplines_from_csv(csv_path)
        
        code2name = {}
        code2intro = {}
        
        for code, info in discipline_data.items():
            code2name[code] = info.get('name', '')
            code2intro[code] = info.get('intro', '')
            
        print(f"âœ… ä»JSONåŠ è½½äº† {len(code2name)} ä¸ªå­¦ç§‘")
        return code2name, code2intro
    
    def _load_disciplines_from_csv(self, csv_path: str) -> Tuple[Dict, Dict]:
        """
        ä»CSVæ–‡ä»¶åŠ è½½å­¦ç§‘ä¿¡æ¯ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        """
        try:
            import pandas as pd
            df = pd.read_csv(csv_path, header=None, names=["raw"])
            code2name = {}
            code2intro = {}
            
            for x in df["raw"]:
                x = str(x).strip()
                if len(x) >= 5 and x[:4].isdigit():
                    code = x[:4]
                    name = x[5:].strip()
                    code2name[code] = name
                    code2intro[code] = name
            
            print(f"âœ… ä»CSVåŠ è½½äº† {len(code2name)} ä¸ªå­¦ç§‘")
            return code2name, code2intro
        except Exception as e:
            print(f"âŒ ä»CSVåŠ è½½å­¦ç§‘ä¹Ÿå¤±è´¥: {e}")
            return {}, {}
    
    def prepare_discipline_texts(self, code2name: Dict, code2intro: Dict, max_intro_length: int = 2000) -> List[str]:
        """
        å‡†å¤‡å­¦ç§‘æ–‡æœ¬ï¼šä»£ç  + åç§° + ä»‹ç»ï¼ˆæˆªæ–­è¿‡é•¿çš„ä»‹ç»ï¼‰
        """
        discipline_texts = []
        for code, name in code2name.items():
            intro = code2intro.get(code, "")
            # æˆªæ–­è¿‡é•¿çš„ä»‹ç»
            if len(intro) > max_intro_length:
                intro = intro[:max_intro_length] + "..."
            # æ„å»ºå­¦ç§‘æè¿°æ–‡æœ¬
            text = f"{code} {name}ã€‚{intro}"
            discipline_texts.append(text)
        return discipline_texts
    
    def get_embeddings_batch(self, texts: List[str]) -> Tensor:
        """
        åˆ†æ‰¹è·å–æ–‡æœ¬çš„åµŒå…¥å‘é‡ï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰
        """
        if not texts:
            return torch.tensor([]).to(self.device)
        
        all_embeddings = []
        
        for i in range(0, len(texts), self.batch_size):
            batch_texts = texts[i:i+self.batch_size]
            
            # Tokenize
            batch_dict = self.tokenizer(
                batch_texts,
                padding=True,
                truncation=True,
                max_length=self.max_length,
                return_tensors="pt",
            )
            batch_dict = {k: v.to(self.device) for k, v in batch_dict.items()}
            
            # æ¨¡å‹æ¨ç†
            with torch.no_grad():
                outputs = self.model(**batch_dict)
            
            # Last token pooling
            embeddings = self.last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])
            
            # å½’ä¸€åŒ–
            embeddings = F.normalize(embeddings, p=2, dim=1)
            
            all_embeddings.append(embeddings.cpu())  # ç§»åˆ°CPUé‡Šæ”¾GPUå†…å­˜
            
            # æ¸…ç†GPUç¼“å­˜
            if self.device == "cuda":
                torch.cuda.empty_cache()
        
        # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„åµŒå…¥
        if all_embeddings:
            return torch.cat(all_embeddings, dim=0).to(self.device)
        else:
            return torch.tensor([]).to(self.device)
    
    def score_single_memory_efficient(self, title: str, abstract: str, topk: int = None) -> List[Tuple[str, float]]:
        """
        å†…å­˜ä¼˜åŒ–çš„å•ç¯‡è®ºæ–‡è¯„åˆ†ï¼ˆåˆ†æ‰¹å¤„ç†å­¦ç§‘ï¼‰
        """
        topk = topk or int(os.getenv("TOPN", "5"))
        
        if not self.code2name:
            return []
        
        # å‡†å¤‡æŸ¥è¯¢æ–‡æœ¬
        query_text = f"æ ‡é¢˜ï¼š{title}ã€‚æ‘˜è¦ï¼š{abstract}"
        instructed_query = self.get_detailed_instruct(query_text)
        
        # è·å–æŸ¥è¯¢åµŒå…¥
        print("ğŸ” è®¡ç®—æŸ¥è¯¢åµŒå…¥...")
        query_embedding = self.get_embeddings_batch([instructed_query])
        if query_embedding.numel() == 0:
            return []
        
        # åˆ†æ‰¹å¤„ç†å­¦ç§‘æ–‡æœ¬
        discipline_texts = self.prepare_discipline_texts(self.code2name, self.code2intro)
        discipline_codes = list(self.code2name.keys())
        
        all_scores = []
        
        print("ğŸ“š åˆ†æ‰¹è®¡ç®—å­¦ç§‘ç›¸ä¼¼åº¦...")
        for i in range(0, len(discipline_texts), self.batch_size):
            batch_texts = discipline_texts[i:i+self.batch_size]
            batch_codes = discipline_codes[i:i+self.batch_size]
            
            # è·å–å½“å‰æ‰¹æ¬¡çš„å­¦ç§‘åµŒå…¥
            discipline_embeddings = self.get_embeddings_batch(batch_texts)
            if discipline_embeddings.numel() == 0:
                continue
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            batch_scores = (query_embedding @ discipline_embeddings.T).squeeze(0)
            batch_scores = batch_scores.cpu().numpy()
            
            # ä¿å­˜åˆ†æ•°å’Œå¯¹åº”çš„å­¦ç§‘ä»£ç 
            for j, score in enumerate(batch_scores):
                all_scores.append((batch_codes[j], float(score)))
            
            # æ¸…ç†GPUç¼“å­˜
            if self.device == "cuda":
                torch.cuda.empty_cache()
        
        # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›topk
        all_scores.sort(key=lambda x: x[1], reverse=True)
        
        # è½¬æ¢ä¸ºåŒ…å«å­¦ç§‘åç§°çš„æ ¼å¼
        formatted_results = []
        for code, score in all_scores[:topk]:
            name = self.code2name.get(code, "")
            formatted_results.append((f"{code} {name}", score))
        
        return formatted_results
    
    def score_batch_memory_efficient(self, titles: List[str], abstracts: List[str], topk: int = None, query_batch_size: int = None) -> List[List[Tuple[str, float]]]:
        """
        å†…å­˜ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†
        """
        topk = topk or int(os.getenv("TOPN", "5"))
        query_batch_size = query_batch_size or max(1, self.batch_size // 4)  # æ›´å°çš„æŸ¥è¯¢æ‰¹å¤§å°
        
        if not self.code2name:
            return [[] for _ in range(len(titles))]
        
        # é¢„è®¡ç®—æ‰€æœ‰å­¦ç§‘åµŒå…¥ï¼ˆåˆ†æ‰¹ï¼‰
        print("ğŸ“š é¢„è®¡ç®—å­¦ç§‘åµŒå…¥...")
        discipline_texts = self.prepare_discipline_texts(self.code2name, self.code2intro)
        discipline_codes = list(self.code2name.keys())
        discipline_embeddings = self.get_embeddings_batch(discipline_texts)
        
        all_results = []
        
        # åˆ†æ‰¹å¤„ç†æŸ¥è¯¢
        for i in range(0, len(titles), query_batch_size):
            batch_titles = titles[i:i+query_batch_size]
            batch_abstracts = abstracts[i:i+query_batch_size]
            
            print(f"ğŸ”¢ å¤„ç†æŸ¥è¯¢æ‰¹æ¬¡ {i//query_batch_size + 1}/{(len(titles)-1)//query_batch_size + 1} (å¤§å°: {len(batch_titles)})")
            
            # å‡†å¤‡æ‰¹å¤„ç†æŸ¥è¯¢
            batch_queries = []
            for title, abstract in zip(batch_titles, batch_abstracts):
                query_text = f"æ ‡é¢˜ï¼š{title}ã€‚æ‘˜è¦ï¼š{abstract}"
                instructed_query = self.get_detailed_instruct(query_text)
                batch_queries.append(instructed_query)
            
            # è·å–æŸ¥è¯¢åµŒå…¥
            query_embeddings = self.get_embeddings_batch(batch_queries)
            
            if query_embeddings.numel() == 0:
                all_results.extend([[] for _ in range(len(batch_queries))])
                continue
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            scores = query_embeddings @ discipline_embeddings.T  # [batch_size, num_disciplines]
            scores = scores.cpu().numpy()
            
            # ä¸ºæ¯ä¸ªæŸ¥è¯¢è·å–topkå­¦ç§‘
            for query_scores in scores:
                top_indices = np.argsort(query_scores)[::-1][:topk]
                results = []
                for idx in top_indices:
                    code = discipline_codes[idx]
                    name = self.code2name.get(code, "")
                    score = float(query_scores[idx])
                    results.append((f"{code} {name}", score))
                all_results.append(results)
            
            # æ¸…ç†GPUç¼“å­˜
            if self.device == "cuda":
                torch.cuda.empty_cache()
        
        return all_results

import pandas as pd
import os
from pathlib import Path
import glob
from typing import List, Tuple
import json

def process_csv_files_with_scorer(scorer, input_dir: str, output_dir: str, batch_size: int = 32, overwrite: bool = False):
    """
    æ‰¹é‡å¤„ç†CSVæ–‡ä»¶ä¸­çš„è®ºæ–‡æ ‡é¢˜å’Œæ‘˜è¦ï¼Œæ›´æ–°list_title_abså­—æ®µ
    
    Args:
        scorer: QwenDisciplineScorerå®ä¾‹
        input_dir: è¾“å…¥CSVæ–‡ä»¶ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        batch_size: æ‰¹å¤„ç†å¤§å°
        overwrite: æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = glob.glob(os.path.join(input_dir, "*.csv"))
    print(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    total_processed = 0
    skipped_files = 0
    
    for csv_file in csv_files:
        filename = os.path.basename(csv_file)
        output_file = os.path.join(output_dir, filename)
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(output_file) and not overwrite:
            print(f"â­ï¸  è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶: {filename}")
            skipped_files += 1
            continue
            
        print(f"\nğŸ” å¤„ç†æ–‡ä»¶: {filename}")
        
        try:
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(csv_file)
            print(f"  è¯»å–åˆ° {len(df)} è¡Œæ•°æ®")
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = ['è®ºæ–‡æ ‡é¢˜', 'CR_æ‘˜è¦', 'list_title_abs']
            if not all(col in df.columns for col in required_columns):
                print(f"  âš ï¸ æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—ï¼Œè·³è¿‡")
                continue
            
            # å‡†å¤‡æ‰¹é‡å¤„ç†æ•°æ®
            titles = []
            abstracts = []
            valid_indices = []
            
            for idx, row in df.iterrows():
                title = str(row['è®ºæ–‡æ ‡é¢˜']) if pd.notna(row['è®ºæ–‡æ ‡é¢˜']) else ""
                abstract = str(row['CR_æ‘˜è¦']) if pd.notna(row['CR_æ‘˜è¦']) else ""
                
                # åªå¤„ç†æœ‰æ ‡é¢˜å’Œæ‘˜è¦çš„æ•°æ®
                if title and abstract:
                    titles.append(title)
                    abstracts.append(abstract)
                    valid_indices.append(idx)
            
            print(f"  âœ… æœ‰æ•ˆæ•°æ®: {len(titles)}/{len(df)}")
            
            if not titles:
                print(f"  âš ï¸ æ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡")
                continue
            
            # åˆ†æ‰¹å¤„ç†ä»¥é¿å…å†…å­˜æº¢å‡º
            all_results = []
            for i in range(0, len(titles), batch_size):
                batch_titles = titles[i:i+batch_size]
                batch_abstracts = abstracts[i:i+batch_size]
                
                print(f"    å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(titles)-1)//batch_size + 1}")
                
                try:
                    batch_results = scorer.score_batch_memory_efficient(
                        batch_titles, 
                        batch_abstracts, 
                        topk=5,
                        query_batch_size=min(8, batch_size)  # æ›´å°çš„æŸ¥è¯¢æ‰¹æ¬¡
                    )
                    all_results.extend(batch_results)
                    
                    # æ¸…ç†å†…å­˜
                    if scorer.device == "cuda":
                        torch.cuda.empty_cache()
                        
                except Exception as e:
                    print(f"    âŒ æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
                    # ä¸ºå¤±è´¥çš„æ‰¹æ¬¡æ·»åŠ ç©ºç»“æœ
                    all_results.extend([[] for _ in range(len(batch_titles))])
            
            # æ›´æ–°list_title_abså­—æ®µ
            updated_count = 0
            for idx, result_idx in enumerate(valid_indices):
                if idx < len(all_results) and all_results[idx]:
                    # å°†ç»“æœè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
                    result_str = json.dumps(all_results[idx], ensure_ascii=False)
                    df.at[result_idx, 'list_title_abs'] = result_str
                    updated_count += 1
            
            # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
            df.to_csv(output_file, index=False, encoding='utf-8')
            
            print(f"  âœ… æ›´æ–°å®Œæˆ: {updated_count}/{len(valid_indices)} è¡Œ")
            print(f"  ğŸ’¾ æ–‡ä»¶å·²ä¿å­˜: {output_file}")
            total_processed += updated_count
            
        except Exception as e:
            print(f"  âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
    print(f"  âœ… æˆåŠŸå¤„ç†: {len(csv_files) - skipped_files} ä¸ªæ–‡ä»¶")
    print(f"  â­ï¸  è·³è¿‡æ–‡ä»¶: {skipped_files} ä¸ª")
    print(f"  ğŸ“ æ€»å…±æ›´æ–°: {total_processed} è¡Œæ•°æ®")

def process_single_csv_with_progress(scorer, csv_file: str, output_file: str, batch_size: int = 16, overwrite: bool = False):
    """
    å¤„ç†å•ä¸ªCSVæ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦
    
    Args:
        scorer: QwenDisciplineScorerå®ä¾‹
        csv_file: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        batch_size: æ‰¹å¤„ç†å¤§å°
        overwrite: æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
    """
    
    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(output_file) and not overwrite:
        print(f"â­ï¸  è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶: {os.path.basename(output_file)}")
        return
    
    print(f"ğŸ” å¤„ç†æ–‡ä»¶: {csv_file}")
    
    try:
        # è¯»å–CSVæ–‡ä»¶
        df = pd.read_csv(csv_file)
        print(f"ğŸ“Š æ•°æ®é‡: {len(df)} è¡Œ")
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—
        if 'è®ºæ–‡æ ‡é¢˜' not in df.columns or 'CR_æ‘˜è¦' not in df.columns:
            print("âŒ æ–‡ä»¶ç¼ºå°‘'è®ºæ–‡æ ‡é¢˜'æˆ–'CR_æ‘˜è¦'åˆ—")
            return
        
        # å‡†å¤‡æ•°æ®
        titles = []
        abstracts = []
        valid_indices = []
        
        for idx, row in df.iterrows():
            title = str(row['è®ºæ–‡æ ‡é¢˜']) if pd.notna(row['è®ºæ–‡æ ‡é¢˜']) else ""
            abstract = str(row['CR_æ‘˜è¦']) if pd.notna(row['CR_æ‘˜è¦']) else ""
            
            if title and abstract and len(abstract) > 10:  # æ‘˜è¦è‡³å°‘10ä¸ªå­—ç¬¦
                titles.append(title)
                abstracts.append(abstract)
                valid_indices.append(idx)
        
        print(f"âœ… æœ‰æ•ˆæ•°æ®: {len(titles)}/{len(df)}")
        
        if not titles:
            print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
            return
        
        # å¤„ç†æ•°æ®
        print("ğŸš€ å¼€å§‹è®¡ç®—å­¦ç§‘åˆ†æ•°...")
        all_results = scorer.score_batch_memory_efficient(
            titles, abstracts, topk=5, query_batch_size=min(8, batch_size)
        )
        
        # æ›´æ–°æ•°æ®æ¡†
        for idx, result_idx in enumerate(valid_indices):
            if idx < len(all_results):
                df.at[result_idx, 'list_title_abs'] = json.dumps(all_results[idx], ensure_ascii=False)
        
        # ä¿å­˜ç»“æœ
        df.to_csv(output_file, index=False, encoding='utf-8')
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
        successful_updates = sum(1 for idx in valid_indices if idx < len(all_results) and all_results[idx])
        print(f"ğŸ“ˆ æˆåŠŸæ›´æ–°: {successful_updates}/{len(valid_indices)}")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def run_discipline_scoring_pipeline(overwrite: bool = False):
    """
    è¿è¡Œå­¦ç§‘è¯„åˆ†æµæ°´çº¿
    
    Args:
        overwrite: æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶
    """
    try:
        # åˆå§‹åŒ–è¯„åˆ†å™¨
        print("ğŸš€ åˆå§‹åŒ–QwenDisciplineScorer...")
        scorer = QwenDisciplineScorer(
            use_flash_attention=False,
            device="cuda" if torch.cuda.is_available() else "cpu"
        )
        
        # è®¾ç½®è·¯å¾„
        input_dir = "./data/04input_data"  # æ ¹æ®æ‚¨çš„å®é™…è·¯å¾„è°ƒæ•´
        output_dir = "./data/05processed_data"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        print("ğŸ“ å¼€å§‹æ‰¹é‡å¤„ç†CSVæ–‡ä»¶...")
        if overwrite:
            print("âš ï¸  è¦†ç›–æ¨¡å¼: å°†è¦†ç›–å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶")
        else:
            print("ğŸ”’ è·³è¿‡æ¨¡å¼: å°†è·³è¿‡å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶")
        
        # æ–¹æ³•1: æ‰¹é‡å¤„ç†æ‰€æœ‰æ–‡ä»¶
        process_csv_files_with_scorer(
            scorer=scorer,
            input_dir=input_dir,
            output_dir=output_dir,
            batch_size=16,  # ä¿å®ˆçš„æ‰¹å¤§å°
            overwrite=overwrite
        )
        
        # æ–¹æ³•2: æˆ–è€…é€ä¸ªæ–‡ä»¶å¤„ç†ï¼ˆå–æ¶ˆæ³¨é‡Šä½¿ç”¨ï¼‰
        # csv_files = glob.glob(os.path.join(input_dir, "*.csv"))
        # for csv_file in csv_files[:1]:  # åªå¤„ç†ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºæµ‹è¯•
        #     filename = os.path.basename(csv_file)
        #     output_file = os.path.join(output_dir, filename)
        #     process_single_csv_with_progress(scorer, csv_file, output_file, overwrite=overwrite)
        
        print("ğŸ‰ å­¦ç§‘è¯„åˆ†æµæ°´çº¿å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

# æ–°å¢å‡½æ•°ï¼šæ£€æŸ¥å¤„ç†è¿›åº¦
def check_processing_progress(input_dir: str, output_dir: str):
    """
    æ£€æŸ¥å¤„ç†è¿›åº¦ï¼Œæ˜¾ç¤ºå“ªäº›æ–‡ä»¶å·²å¤„ç†ï¼Œå“ªäº›æœªå¤„ç†
    """
    input_files = set([os.path.basename(f) for f in glob.glob(os.path.join(input_dir, "*.csv"))])
    output_files = set([os.path.basename(f) for f in glob.glob(os.path.join(output_dir, "*.csv"))])
    
    processed = input_files & output_files
    unprocessed = input_files - output_files
    
    print(f"\nğŸ“Š å¤„ç†è¿›åº¦æ£€æŸ¥:")
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"âœ… å·²å¤„ç†æ–‡ä»¶: {len(processed)} ä¸ª")
    print(f"â³ æœªå¤„ç†æ–‡ä»¶: {len(unprocessed)} ä¸ª")
    
    if unprocessed:
        print("\nğŸ“‹ æœªå¤„ç†æ–‡ä»¶åˆ—è¡¨:")
        for file in sorted(unprocessed):
            print(f"  - {file}")

# æµ‹è¯•å‡½æ•°
def test_small_batch():
    """
    æµ‹è¯•å°æ‰¹é‡å¤„ç†
    """
    try:
        print("ğŸ§ª æµ‹è¯•å°æ‰¹é‡å¤„ç†...")
        scorer = QwenDisciplineScorer(
            use_flash_attention=False,
            device="cuda" if torch.cuda.is_available() else "cpu"
        )
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = [
            {
                "è®ºæ–‡æ ‡é¢˜": "æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨",
                "CR_æ‘˜è¦": "æœ¬æ–‡ç ”ç©¶äº†æ·±åº¦å­¦ä¹ æŠ€æœ¯åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„å„ç§åº”ç”¨ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ†ç±»ã€æœºå™¨ç¿»è¯‘å’Œæƒ…æ„Ÿåˆ†æç­‰ã€‚"
            },
            {
                "è®ºæ–‡æ ‡é¢˜": "ç»æµå­¦ä¸­çš„å¸‚åœºåˆ†æ",
                "CR_æ‘˜è¦": "æœ¬æ–‡é€šè¿‡å®è¯åˆ†æç ”ç©¶äº†å¸‚åœºç»æµä¸­çš„ä¾›éœ€å…³ç³»å’Œä»·æ ¼å½¢æˆæœºåˆ¶ã€‚"
            }
        ]
        
        titles = [item["è®ºæ–‡æ ‡é¢˜"] for item in test_data]
        abstracts = [item["CR_æ‘˜è¦"] for item in test_data]
        
        results = scorer.score_batch_memory_efficient(titles, abstracts, topk=3)
        
        print("æµ‹è¯•ç»“æœ:")
        for i, (title, result) in enumerate(zip(titles, results)):
            print(f"è®ºæ–‡ {i+1}: {title}")
            for discipline, score in result:
                print(f"  {discipline}: {score:.4f}")
            print()
            
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    # æ£€æŸ¥å¤„ç†è¿›åº¦
    input_dir = "./data/04input_data"
    output_dir = "./data/05processed_data"
    check_processing_progress(input_dir, output_dir)
    
    # è¿è¡Œæµ‹è¯•
    print("\nğŸ§ª è¿è¡Œå°æ‰¹é‡æµ‹è¯•...")
    test_small_batch()
    
    # è¿è¡Œå®Œæ•´æµæ°´çº¿ï¼ˆé»˜è®¤ä¸è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶ï¼‰
    print("\nğŸš€ è¿è¡Œå®Œæ•´æµæ°´çº¿...")
    run_discipline_scoring_pipeline(overwrite=True)
    
    # å¦‚æœéœ€è¦è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶ï¼Œä½¿ç”¨ï¼š
    # run_discipline_scoring_pipeline(overwrite=True)